# Robots.txt para Acortador de URLs
# Permite indexación controlada del sitio

User-agent: *

# Permitir páginas principales
Allow: /
Allow: /stats.php
Allow: /diagnostics.php

# Bloquear área de administración
Disallow: /admin/
Disallow: /setup.php

# Bloquear archivos de configuración
Disallow: /conf.php
Disallow: /functions.php
Disallow: /.htaccess
Disallow: /database.sql

# Bloquear archivos temporales y backups
Disallow: /*.bak
Disallow: /*.tmp
Disallow: /*.log
Disallow: /*~

# Permitir acceso a URLs acortadas
# (Las URLs cortas usan códigos alfanuméricos)
Allow: /[a-zA-Z0-9]*

# Configuración específica para diferentes bots
User-agent: Googlebot
Crawl-delay: 1

User-agent: Bingbot
Crawl-delay: 2

User-agent: Slurp
Crawl-delay: 2

# Bloquear bots maliciosos comunes
User-agent: AhrefsBot
Disallow: /

User-agent: MJ12bot
Disallow: /

User-agent: DotBot
Disallow: /

# Ubicación del sitemap (crear cuando tengas contenido estático)
# Sitemap: https://tu-dominio.com/sitemap.xml
